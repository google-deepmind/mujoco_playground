{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkYHwCqk7W-"
      },
      "source": [
        "![MuJoCo banner](https://raw.githubusercontent.com/google-deepmind/mujoco/main/banner.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSdkbmGN2K-"
      },
      "source": [
        "### Copyright notice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UbO9uhtBSX5"
      },
      "source": [
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003eCopyright 2024 DeepMind Technologies Limited.\u003c/small\u003e\u003c/p\u003e\n",
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003eLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at \u003ca href=\"http://www.apache.org/licenses/LICENSE-2.0\"\u003ehttp://www.apache.org/licenses/LICENSE-2.0\u003c/a\u003e.\u003c/small\u003e\u003c/small\u003e\u003c/p\u003e\n",
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003eUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\u003c/small\u003e\u003c/small\u003e\u003c/p\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNIJkb_FM2Ux"
      },
      "source": [
        "# MuJoCo Playground Environments \u003ch1\u003e\u003ccenter\u003e\u003ca href=\"https://colab.research.google.com/github/google-deepmind/mujoco_playground/blob/main/learning/training.ipynb\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/\u003e\u003c/a\u003e\u003c/center\u003e\u003c/h1\u003e\n",
        "\n",
        "This notebook provides examples training MuJoCo Playground enviornments.\n",
        "\n",
        "**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \"Runtime \u003e Change runtime type\".\n",
        "\n",
        "The notebook is divided into sections based on the types of environments in MuJoCo Playground:\n",
        "\n",
        "1. [DM Control Suite](#scrollTo=a3NXzZCjTskz): A fork of DM Control Suite environments that run using [MJX](https://mujoco.readthedocs.io/en/stable/mjx.html).\n",
        "2. [Locomotion](#scrollTo=JhOUCIWbXL6f): Locomotion environments for quadrupeds and humanoids.\n",
        "3. [Manipulation](#scrollTo=fjEiBqMrXNVM): Manipulation environments for both single and bi-arm platforms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "Xqo7pyX-n72M"
      },
      "outputs": [],
      "source": [
        "!pip install mujoco\n",
        "\n",
        "!pip install mujoco_mjx\n",
        "!pip install brax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "id": "IbZxYDxzoz5R"
      },
      "outputs": [],
      "source": [
        "# @title Check if MuJoCo installation was successful\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.'\n",
        "  )\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "\n",
        "  mujoco.MjModel.from_xml_string('\u003cmujoco/\u003e')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
        "  )\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "id": "T5f4w3Kq2X14"
      },
      "outputs": [],
      "source": [
        "# @title Import packages for plotting and creating graphics\n",
        "import itertools\n",
        "import time\n",
        "from typing import Callable, List, NamedTuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print(\"Installing mediapy:\")\n",
        "!command -v ffmpeg \u003e/dev/null || (apt update \u0026\u0026 apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "id": "ObF1UXrkb0Nd"
      },
      "outputs": [],
      "source": [
        "# @title Import MuJoCo, MJX, and Brax\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import os\n",
        "from typing import Any, Dict, Sequence, Tuple, Union\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.base import State as PipelineState\n",
        "from brax.envs.base import Env, PipelineEnv, State\n",
        "from brax.io import html, mjcf, model\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import networks as sac_networks\n",
        "from brax.training.agents.sac import train as sac\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from flax.training import orbax_utils\n",
        "from IPython.display import HTML, clear_output\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx\n",
        "from mujoco_playground import dm_control_suite\n",
        "from mujoco_playground import locomotion\n",
        "from mujoco_playground import locomotion, wrapper\n",
        "from mujoco_playground import manipulation\n",
        "from mujoco_playground import wrapper\n",
        "import numpy as np\n",
        "from orbax import checkpoint as ocp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3NXzZCjTskz"
      },
      "source": [
        "# DM Control Suite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "id": "CilNmELAdeNk"
      },
      "outputs": [],
      "source": [
        "env_name = \"FishSwim\"  # @param [\"AcrobotSwingup\", \"AcrobotSwingupSparse\", \"BallInCup\", \"CartpoleBalance\", \"CartpoleBalanceSparse\", \"CartpoleSwingup\", \"CartpoleSwingupSparse\", \"CheetahRun\", \"FingerSpin\", \"FingerTurnEasy\", \"FingerTurnHard\", \"FishSwim\", \"HopperHop\", \"HopperStand\", \"HumanoidStand\", \"HumanoidWalk\", \"HumanoidRun\", \"PendulumSwingup\", \"PointMass\", \"ReacherEasy\", \"ReacherHard\", \"SwimmerSwimmer6\", \"WalkerRun\", \"WalkerStand\", \"WalkerWalk\"]\n",
        "CAMERAS = {\n",
        "    \"AcrobotSwingup\": \"fixed\",\n",
        "    \"AcrobotSwingupSparse\": \"fixed\",\n",
        "    \"BallInCup\": \"cam0\",\n",
        "    \"CartpoleBalance\": \"fixed\",\n",
        "    \"CartpoleBalanceSparse\": \"fixed\",\n",
        "    \"CartpoleSwingup\": \"fixed\",\n",
        "    \"CartpoleSwingupSparse\": \"fixed\",\n",
        "    \"CheetahRun\": \"side\",\n",
        "    \"FingerSpin\": \"cam0\",\n",
        "    \"FingerTurnEasy\": \"cam0\",\n",
        "    \"FingerTurnHard\": \"cam0\",\n",
        "    \"FishSwim\": \"fixed_top\",\n",
        "    \"HopperHop\": \"cam0\",\n",
        "    \"HopperStand\": \"cam0\",\n",
        "    \"HumanoidStand\": \"side\",\n",
        "    \"HumanoidWalk\": \"side\",\n",
        "    \"HumanoidRun\": \"side\",\n",
        "    \"PendulumSwingup\": \"fixed\",\n",
        "    \"PointMass\": \"cam0\",\n",
        "    \"ReacherEasy\": \"fixed\",\n",
        "    \"ReacherHard\": \"fixed\",\n",
        "    \"SwimmerSwimmer6\": \"tracking1\",\n",
        "    \"WalkerRun\": \"side\",\n",
        "    \"WalkerWalk\": \"side\",\n",
        "    \"WalkerStand\": \"side\",\n",
        "}\n",
        "camera_name = CAMERAS[env_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "6m1K6y4IOUj_"
      },
      "outputs": [],
      "source": [
        "env_cfg = dm_control_suite.get_default_config(env_name)\n",
        "env = dm_control_suite.load(env_name, config=env_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHkrJhAOUj_"
      },
      "source": [
        "## Visualize the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "9Ry7wWduOUkA"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "WR5DX0SWOUkA"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "rollout = [state]\n",
        "\n",
        "f = 0.5\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            state.data.time * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.array(action)\n",
        "  state = jit_step(state, action)\n",
        "  rollout.append(state)\n",
        "\n",
        "frames = env.render(rollout, camera=CAMERAS[env_name])\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuI8_ioCOUkB"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "afAaOGzSoNMd"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.learning import dm_control_suite_params\n",
        "\n",
        "ppo_params = dm_control_suite_params.brax_ppo_config(env_name)\n",
        "sac_params = dm_control_suite_params.brax_sac_config(env_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5MNLlatbS27"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "N5KgRSAZbSEX"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_params), progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "YrD6T1VWbSJD"
      },
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=wrapper.BraxEnvWrapper(env)\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "80esJi__b6J2"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "HsbR2AIRb6J2"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every], camera=CAMERAS[env_name])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
        "\n",
        "plt.plot(np.convolve(rewards, np.ones(100) / 100, mode=\"valid\"))\n",
        "plt.xlabel(\"time step\")\n",
        "plt.ylabel(\"reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpRJnuuXb7Ax"
      },
      "source": [
        "### SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "besM1HxqOUkB"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, sac_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    sac.train, **dict(sac_params), progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "XkKerfRjOUkB"
      },
      "outputs": [],
      "source": [
        "network_factory = functools.partial(\n",
        "    sac_networks.make_sac_networks,\n",
        "    q_network_layer_norm=sac_params.network_factory.q_network_layer_norm,\n",
        ")\n",
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=wrapper.BraxEnvWrapper(env), network_factory=network_factory\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "Yw_vewrKOUkB"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "VJFfqcwoOUkB"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every], camera=CAMERAS[env_name])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
        "\n",
        "plt.plot(np.convolve(rewards, np.ones(100) / 100, mode=\"valid\"))\n",
        "plt.xlabel(\"time step\")\n",
        "plt.ylabel(\"reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhOUCIWbXL6f"
      },
      "source": [
        "# Locomotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "id": "YhVHAs18uva2"
      },
      "outputs": [],
      "source": [
        "env_name = \"BarkourJoystick\"  # @param [\"BarkourJoystick\", \"Go1Joystick\", \"Go1Getup\", \"H1Joystick\"]\n",
        "CAMERAS = {\n",
        "    \"BarkourJoystick\": \"track\",\n",
        "    \"Go1Joystick\": \"track\",\n",
        "    \"Go1Getup\": \"track\",\n",
        "    \"H1Joystick\": \"side\",\n",
        "}\n",
        "camera_name = CAMERAS[env_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "oS4Y20KHuva2"
      },
      "outputs": [],
      "source": [
        "env_cfg = locomotion.get_default_config(env_name)\n",
        "env = locomotion.load(env_name, config=env_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw7dX9-6uva2"
      },
      "source": [
        "## Visualize the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "oQOQmgjkuva2"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "OIlrCg6auva2"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "rollout = [state]\n",
        "\n",
        "f = 0.2\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            state.data.time * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.array(action)\n",
        "  state = jit_step(state, action)\n",
        "  rollout.append(state)\n",
        "\n",
        "frames = env.render(rollout, camera=CAMERAS[env_name])\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O5Gg2YNw4ZF"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "t2geBsy7wWzw"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.learning import locomotion_params\n",
        "\n",
        "ppo_params = locomotion_params.brax_ppo_config(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "URrDto99w3ML"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 50])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "\n",
        "training_params = dict(ppo_params)\n",
        "del training_params[\"network_factory\"]\n",
        "train_fn = functools.partial(ppo.train, **training_params, progress_fn=progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "BUT_1R3ww3MM"
      },
      "outputs": [],
      "source": [
        "network_factory = functools.partial(\n",
        "    ppo_networks.make_ppo_networks,\n",
        "    policy_hidden_layer_sizes=ppo_params.network_factory.policy_hidden_layer_sizes,\n",
        ")\n",
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=wrapper.BraxEnvWrapper(env)\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "ugJUCEhXw3MM"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "2idzUqFxw3MM"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every], camera=CAMERAS[env_name])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
        "\n",
        "plt.plot(np.convolve(rewards, np.ones(100) / 100, mode=\"valid\"))\n",
        "plt.xlabel(\"time step\")\n",
        "plt.ylabel(\"reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjEiBqMrXNVM"
      },
      "source": [
        "# Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "Cl7HANGzuwxb"
      },
      "outputs": [],
      "source": [
        "env_name = \"AlohaSinglePeg\"  # @param [\"AlohaSinglePeg\"]\n",
        "CAMERAS = {\n",
        "    \"AlohaSinglePeg\": \"teleoperator_pov\",\n",
        "}\n",
        "camera_name = CAMERAS[env_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "seLd89wluwxc"
      },
      "outputs": [],
      "source": [
        "env_cfg = manipulation.get_default_config(env_name)\n",
        "env = manipulation.load(env_name, config=env_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XKW-C4iuwxc"
      },
      "source": [
        "## Visualize the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "p-I00hfn4xXq"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "MhrpwScc4xXq"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "rollout = [state]\n",
        "\n",
        "f = 0.2\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            state.data.time * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.array(action)\n",
        "  state = jit_step(state, action)\n",
        "  rollout.append(state)\n",
        "\n",
        "frames = env.render(rollout, camera=CAMERAS[env_name])\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ7nVkxw44x2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "_V23psMk44x2"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.learning import manipulation_params\n",
        "\n",
        "ppo_params = manipulation_params.brax_ppo_config(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "7ZWS5Sr_44x2"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 15_000])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "\n",
        "training_params = dict(ppo_params)\n",
        "del training_params[\"network_factory\"]\n",
        "train_fn = functools.partial(ppo.train, **training_params, progress_fn=progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "MD-qZP9-44x2"
      },
      "outputs": [],
      "source": [
        "network_factory = functools.partial(\n",
        "    ppo_networks.make_ppo_networks,\n",
        "    policy_hidden_layer_sizes=ppo_params.network_factory.policy_hidden_layer_sizes,\n",
        ")\n",
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=wrapper.BraxEnvWrapper(env)\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "ahMz0E2A44x3"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "id": "XX4geiWA44x3"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every], camera=CAMERAS[env_name])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
        "\n",
        "plt.plot(np.convolve(rewards, np.ones(100) / 100, mode=\"valid\"))\n",
        "plt.xlabel(\"time step\")\n",
        "plt.ylabel(\"reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtrAqns35sI"
      },
      "source": [
        "ðŸ™Œ See you soon!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
